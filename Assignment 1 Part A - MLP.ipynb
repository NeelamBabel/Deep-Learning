{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils.np_utils import to_categorical   \n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:\n",
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n",
      "Shape of test data:\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training data:\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"Shape of test data:\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example training images and their labels: [6, 9, 9, 4, 1]\n",
      "Corresponding classes for the labels: ['frog', 'truck', 'truck', 'deer', 'automobile']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6IAAAC8CAYAAABizBPxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130f4e4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cifar_classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "print('Example training images and their labels: ' + str([x[0] for x in y_train[0:5]])) \n",
    "print('Corresponding classes for the labels: ' + str([cifar_classes[x[0]] for x in y_train[0:5]]))\n",
    "\n",
    "f, axarr = plt.subplots(1, 5)\n",
    "f.set_size_inches(16, 6)\n",
    "\n",
    "for i in range(5):\n",
    "    img = X_train[i]\n",
    "    axarr[i].imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform label indices to one-hot encoded vectors\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Transform images from (32,32,3) to 3072-dimensional vectors (32*32*3)\n",
    "\n",
    "X_train = np.reshape(X_train,(50000,3072))\n",
    "X_test = np.reshape(X_test,(10000,3072))\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Normalization of pixel values (to [0-1] range)\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=3072))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "8s - loss: 1.4364 - acc: 0.4894 - val_loss: 1.4808 - val_acc: 0.4777\n",
      "Epoch 2/15\n",
      "9s - loss: 1.4006 - acc: 0.5010 - val_loss: 1.5004 - val_acc: 0.4744\n",
      "Epoch 3/15\n",
      "7s - loss: 1.3773 - acc: 0.5086 - val_loss: 1.4701 - val_acc: 0.4829\n",
      "Epoch 4/15\n",
      "8s - loss: 1.3571 - acc: 0.5158 - val_loss: 1.4740 - val_acc: 0.4783\n",
      "Epoch 5/15\n",
      "7s - loss: 1.3389 - acc: 0.5200 - val_loss: 1.4597 - val_acc: 0.4838\n",
      "Epoch 6/15\n",
      "8s - loss: 1.3186 - acc: 0.5306 - val_loss: 1.4407 - val_acc: 0.4944\n",
      "Epoch 7/15\n",
      "8s - loss: 1.2998 - acc: 0.5342 - val_loss: 1.4561 - val_acc: 0.4907\n",
      "Epoch 8/15\n",
      "8s - loss: 1.2830 - acc: 0.5427 - val_loss: 1.4415 - val_acc: 0.4916\n",
      "Epoch 9/15\n",
      "8s - loss: 1.2676 - acc: 0.5458 - val_loss: 1.4396 - val_acc: 0.4986\n",
      "Epoch 10/15\n",
      "8s - loss: 1.2480 - acc: 0.5545 - val_loss: 1.4389 - val_acc: 0.4962\n",
      "Epoch 11/15\n",
      "8s - loss: 1.2332 - acc: 0.5608 - val_loss: 1.4122 - val_acc: 0.5059\n",
      "Epoch 12/15\n",
      "8s - loss: 1.2155 - acc: 0.5660 - val_loss: 1.4329 - val_acc: 0.5037\n",
      "Epoch 13/15\n",
      "8s - loss: 1.2020 - acc: 0.5746 - val_loss: 1.4298 - val_acc: 0.5033\n",
      "Epoch 14/15\n",
      "8s - loss: 1.1862 - acc: 0.5778 - val_loss: 1.4467 - val_acc: 0.5036\n",
      "Epoch 15/15\n",
      "9s - loss: 1.1727 - acc: 0.5822 - val_loss: 1.4333 - val_acc: 0.5002\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=15, batch_size=100, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=3072))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9s - loss: 1.8359 - acc: 0.3366 - val_loss: 1.7399 - val_acc: 0.3789\n",
      "Epoch 2/10\n",
      "9s - loss: 1.6405 - acc: 0.4139 - val_loss: 1.6602 - val_acc: 0.4123\n",
      "Epoch 3/10\n",
      "8s - loss: 1.5609 - acc: 0.4417 - val_loss: 1.6058 - val_acc: 0.4198\n",
      "Epoch 4/10\n",
      "9s - loss: 1.5061 - acc: 0.4605 - val_loss: 1.5225 - val_acc: 0.4615\n",
      "Epoch 5/10\n",
      "9s - loss: 1.4544 - acc: 0.4806 - val_loss: 1.5185 - val_acc: 0.4631\n",
      "Epoch 6/10\n",
      "9s - loss: 1.4163 - acc: 0.4944 - val_loss: 1.4958 - val_acc: 0.4784\n",
      "Epoch 7/10\n",
      "9s - loss: 1.3806 - acc: 0.5043 - val_loss: 1.5461 - val_acc: 0.4509\n",
      "Epoch 8/10\n",
      "9s - loss: 1.3517 - acc: 0.5153 - val_loss: 1.5135 - val_acc: 0.4616\n",
      "Epoch 9/10\n",
      "9s - loss: 1.3240 - acc: 0.5259 - val_loss: 1.4446 - val_acc: 0.4957\n",
      "Epoch 10/10\n",
      "10s - loss: 1.2896 - acc: 0.5399 - val_loss: 1.4258 - val_acc: 0.4996\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.4023698236465454, 0.50739999999999996]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing the Number Of Epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Decreasing the Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=3072))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "10s - loss: 1.8239 - acc: 0.3433 - val_loss: 1.7559 - val_acc: 0.3691\n",
      "Epoch 2/5\n",
      "9s - loss: 1.6434 - acc: 0.4108 - val_loss: 1.6306 - val_acc: 0.4270\n",
      "Epoch 3/5\n",
      "9s - loss: 1.5536 - acc: 0.4455 - val_loss: 1.5913 - val_acc: 0.4305\n",
      "Epoch 4/5\n",
      "9s - loss: 1.4945 - acc: 0.4640 - val_loss: 1.5521 - val_acc: 0.4471\n",
      "Epoch 5/5\n",
      "9s - loss: 1.4494 - acc: 0.4798 - val_loss: 1.4954 - val_acc: 0.4739\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=5, batch_size=100, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.466035038948059, 0.47410000000000002]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Increasing the Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "9s - loss: 1.4119 - acc: 0.4937 - val_loss: 1.4900 - val_acc: 0.4720\n",
      "Epoch 2/20\n",
      "10s - loss: 1.3755 - acc: 0.5067 - val_loss: 1.5018 - val_acc: 0.4747\n",
      "Epoch 3/20\n",
      "9s - loss: 1.3417 - acc: 0.5198 - val_loss: 1.4730 - val_acc: 0.4780\n",
      "Epoch 4/20\n",
      "8s - loss: 1.3113 - acc: 0.5310 - val_loss: 1.4671 - val_acc: 0.4873\n",
      "Epoch 5/20\n",
      "9s - loss: 1.2825 - acc: 0.5406 - val_loss: 1.4959 - val_acc: 0.4775\n",
      "Epoch 6/20\n",
      "8s - loss: 1.2525 - acc: 0.5520 - val_loss: 1.4333 - val_acc: 0.4982\n",
      "Epoch 7/20\n",
      "9s - loss: 1.2288 - acc: 0.5581 - val_loss: 1.4791 - val_acc: 0.4862\n",
      "Epoch 8/20\n",
      "9s - loss: 1.2028 - acc: 0.5682 - val_loss: 1.4615 - val_acc: 0.4956\n",
      "Epoch 9/20\n",
      "9s - loss: 1.1732 - acc: 0.5791 - val_loss: 1.4560 - val_acc: 0.5011\n",
      "Epoch 10/20\n",
      "9s - loss: 1.1484 - acc: 0.5873 - val_loss: 1.4606 - val_acc: 0.4949\n",
      "Epoch 11/20\n",
      "8s - loss: 1.1252 - acc: 0.5962 - val_loss: 1.4673 - val_acc: 0.5064\n",
      "Epoch 12/20\n",
      "9s - loss: 1.1056 - acc: 0.6029 - val_loss: 1.4892 - val_acc: 0.4934\n",
      "Epoch 13/20\n",
      "9s - loss: 1.0698 - acc: 0.6160 - val_loss: 1.5288 - val_acc: 0.4978\n",
      "Epoch 14/20\n",
      "9s - loss: 1.0506 - acc: 0.6224 - val_loss: 1.4785 - val_acc: 0.5003\n",
      "Epoch 15/20\n",
      "8s - loss: 1.0265 - acc: 0.6292 - val_loss: 1.4749 - val_acc: 0.5153\n",
      "Epoch 16/20\n",
      "9s - loss: 1.0014 - acc: 0.6397 - val_loss: 1.5163 - val_acc: 0.4987\n",
      "Epoch 17/20\n",
      "9s - loss: 0.9757 - acc: 0.6491 - val_loss: 1.5589 - val_acc: 0.4958\n",
      "Epoch 18/20\n",
      "8s - loss: 0.9548 - acc: 0.6550 - val_loss: 1.5268 - val_acc: 0.4992\n",
      "Epoch 19/20\n",
      "9s - loss: 0.9314 - acc: 0.6643 - val_loss: 1.5469 - val_acc: 0.4980\n",
      "Epoch 20/20\n",
      "8s - loss: 0.9068 - acc: 0.6739 - val_loss: 1.6021 - val_acc: 0.4949\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=20, batch_size=100, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.580778101682663, 0.49359999626874923]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Batch Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decreasing the Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "12s - loss: 1.1562 - acc: 0.5842 - val_loss: 1.6016 - val_acc: 0.4795\n",
      "Epoch 2/10\n",
      "12s - loss: 1.1244 - acc: 0.5949 - val_loss: 1.7054 - val_acc: 0.4674\n",
      "Epoch 3/10\n",
      "11s - loss: 1.1145 - acc: 0.5977 - val_loss: 1.6851 - val_acc: 0.4678\n",
      "Epoch 4/10\n",
      "12s - loss: 1.0803 - acc: 0.6107 - val_loss: 1.5762 - val_acc: 0.4889\n",
      "Epoch 5/10\n",
      "12s - loss: 1.0587 - acc: 0.6207 - val_loss: 1.6326 - val_acc: 0.4758\n",
      "Epoch 6/10\n",
      "13s - loss: 1.0363 - acc: 0.6287 - val_loss: 1.5872 - val_acc: 0.4859\n",
      "Epoch 7/10\n",
      "12s - loss: 1.0277 - acc: 0.6318 - val_loss: 1.6636 - val_acc: 0.4793\n",
      "Epoch 8/10\n",
      "12s - loss: 1.0095 - acc: 0.6354 - val_loss: 1.6608 - val_acc: 0.4849\n",
      "Epoch 9/10\n",
      "12s - loss: 0.9998 - acc: 0.6418 - val_loss: 1.6935 - val_acc: 0.4798\n",
      "Epoch 10/10\n",
      "11s - loss: 0.9865 - acc: 0.6446 - val_loss: 1.8618 - val_acc: 0.4584\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=10, batch_size=60, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=60, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.8036502594947814, 0.46559999877214431]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "8s - loss: 0.6938 - acc: 0.7504 - val_loss: 1.7491 - val_acc: 0.5144\n",
      "Epoch 2/10\n",
      "7s - loss: 0.5790 - acc: 0.7908 - val_loss: 1.8910 - val_acc: 0.5172\n",
      "Epoch 3/10\n",
      "7s - loss: 0.5296 - acc: 0.8107 - val_loss: 1.9738 - val_acc: 0.5157\n",
      "Epoch 4/10\n",
      "7s - loss: 0.4875 - acc: 0.8235 - val_loss: 2.0128 - val_acc: 0.5141\n",
      "Epoch 5/10\n",
      "7s - loss: 0.4570 - acc: 0.8363 - val_loss: 2.1089 - val_acc: 0.5070\n",
      "Epoch 6/10\n",
      "7s - loss: 0.4318 - acc: 0.8452 - val_loss: 2.1788 - val_acc: 0.5066\n",
      "Epoch 7/10\n",
      "7s - loss: 0.3949 - acc: 0.8584 - val_loss: 2.2444 - val_acc: 0.5094\n",
      "Epoch 8/10\n",
      "7s - loss: 0.3751 - acc: 0.8659 - val_loss: 2.3385 - val_acc: 0.5059\n",
      "Epoch 9/10\n",
      "7s - loss: 0.3592 - acc: 0.8720 - val_loss: 2.4280 - val_acc: 0.5077\n",
      "Epoch 10/10\n",
      "7s - loss: 0.3381 - acc: 0.8783 - val_loss: 2.4646 - val_acc: 0.5078\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=10, batch_size=160, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=160, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[2.4110390739440919, 0.51260000181198118]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing epchs and batch size both just to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "8s - loss: 0.3159 - acc: 0.8860 - val_loss: 2.5593 - val_acc: 0.5034\n",
      "Epoch 2/15\n",
      "11s - loss: 0.3047 - acc: 0.8926 - val_loss: 2.6038 - val_acc: 0.4964\n",
      "Epoch 3/15\n",
      "11s - loss: 0.2945 - acc: 0.8946 - val_loss: 2.7150 - val_acc: 0.5032\n",
      "Epoch 4/15\n",
      "9s - loss: 0.2738 - acc: 0.9015 - val_loss: 2.8194 - val_acc: 0.5018\n",
      "Epoch 5/15\n",
      "7s - loss: 0.2606 - acc: 0.9080 - val_loss: 2.8187 - val_acc: 0.5028\n",
      "Epoch 6/15\n",
      "8s - loss: 0.2526 - acc: 0.9111 - val_loss: 2.9204 - val_acc: 0.4969\n",
      "Epoch 7/15\n",
      "8s - loss: 0.2685 - acc: 0.9027 - val_loss: 2.9122 - val_acc: 0.5030\n",
      "Epoch 8/15\n",
      "7s - loss: 0.2634 - acc: 0.9053 - val_loss: 3.0190 - val_acc: 0.4964\n",
      "Epoch 9/15\n",
      "7s - loss: 0.2570 - acc: 0.9075 - val_loss: 3.1096 - val_acc: 0.4892\n",
      "Epoch 10/15\n",
      "8s - loss: 0.2551 - acc: 0.9077 - val_loss: 3.1135 - val_acc: 0.4985\n",
      "Epoch 11/15\n",
      "8s - loss: 0.2446 - acc: 0.9104 - val_loss: 3.1723 - val_acc: 0.4935\n",
      "Epoch 12/15\n",
      "9s - loss: 0.2593 - acc: 0.9065 - val_loss: 3.2181 - val_acc: 0.4930\n",
      "Epoch 13/15\n",
      "8s - loss: 0.2468 - acc: 0.9097 - val_loss: 3.2803 - val_acc: 0.4929\n",
      "Epoch 14/15\n",
      "8s - loss: 0.2273 - acc: 0.9179 - val_loss: 3.2507 - val_acc: 0.4976\n",
      "Epoch 15/15\n",
      "8s - loss: 0.2275 - acc: 0.9169 - val_loss: 3.2877 - val_acc: 0.4914\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=15, batch_size=160, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=160, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[3.2566409950256348, 0.48790000081062318]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Configuation \n",
    "\n",
    "a. Number of neurons in a layer - Decreasing the number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=3072))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "6s - loss: 1.8381 - acc: 0.3381 - val_loss: 1.7141 - val_acc: 0.3848\n",
      "Epoch 2/10\n",
      "6s - loss: 1.6375 - acc: 0.4187 - val_loss: 1.6338 - val_acc: 0.4269\n",
      "Epoch 3/10\n",
      "5s - loss: 1.5565 - acc: 0.4459 - val_loss: 1.5690 - val_acc: 0.4436\n",
      "Epoch 4/10\n",
      "6s - loss: 1.4977 - acc: 0.4666 - val_loss: 1.5401 - val_acc: 0.4547\n",
      "Epoch 5/10\n",
      "6s - loss: 1.4567 - acc: 0.4809 - val_loss: 1.4924 - val_acc: 0.4704\n",
      "Epoch 6/10\n",
      "5s - loss: 1.4204 - acc: 0.4943 - val_loss: 1.4786 - val_acc: 0.4781\n",
      "Epoch 7/10\n",
      "5s - loss: 1.3833 - acc: 0.5087 - val_loss: 1.4862 - val_acc: 0.4749\n",
      "Epoch 8/10\n",
      "5s - loss: 1.3616 - acc: 0.5146 - val_loss: 1.4892 - val_acc: 0.4736\n",
      "Epoch 9/10\n",
      "5s - loss: 1.3335 - acc: 0.5245 - val_loss: 1.4672 - val_acc: 0.4862\n",
      "Epoch 10/10\n",
      "5s - loss: 1.3061 - acc: 0.5355 - val_loss: 1.4176 - val_acc: 0.4994\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.3954704895019532, 0.50560000000000005]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network Configuation \n",
    "\n",
    "a. Number of neurons in a layer - Increasing the number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=3072))\n",
    "model.add(Dense(350, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9s - loss: 1.8295 - acc: 0.3443 - val_loss: 1.7242 - val_acc: 0.3790\n",
      "Epoch 2/10\n",
      "8s - loss: 1.6311 - acc: 0.4169 - val_loss: 1.6008 - val_acc: 0.4349\n",
      "Epoch 3/10\n",
      "8s - loss: 1.5473 - acc: 0.4493 - val_loss: 1.5543 - val_acc: 0.4465\n",
      "Epoch 4/10\n",
      "10s - loss: 1.4814 - acc: 0.4738 - val_loss: 1.5332 - val_acc: 0.4587\n",
      "Epoch 5/10\n",
      "9s - loss: 1.4378 - acc: 0.4885 - val_loss: 1.4737 - val_acc: 0.4832\n",
      "Epoch 6/10\n",
      "9s - loss: 1.3971 - acc: 0.5035 - val_loss: 1.4641 - val_acc: 0.4873\n",
      "Epoch 7/10\n",
      "9s - loss: 1.3565 - acc: 0.5175 - val_loss: 1.4532 - val_acc: 0.4977\n",
      "Epoch 8/10\n",
      "8s - loss: 1.3284 - acc: 0.5257 - val_loss: 1.4165 - val_acc: 0.5039\n",
      "Epoch 9/10\n",
      "9s - loss: 1.2970 - acc: 0.5374 - val_loss: 1.4226 - val_acc: 0.4969\n",
      "Epoch 10/10\n",
      "8s - loss: 1.2635 - acc: 0.5499 - val_loss: 1.4012 - val_acc: 0.5089\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.3866081304550171, 0.50890000000000002]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Decreasing Number of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=3072))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9s - loss: 1.8168 - acc: 0.3564 - val_loss: 1.7223 - val_acc: 0.3954\n",
      "Epoch 2/10\n",
      "8s - loss: 1.6363 - acc: 0.4222 - val_loss: 1.6643 - val_acc: 0.4216\n",
      "Epoch 3/10\n",
      "8s - loss: 1.5646 - acc: 0.4471 - val_loss: 1.6255 - val_acc: 0.4256\n",
      "Epoch 4/10\n",
      "8s - loss: 1.5151 - acc: 0.4656 - val_loss: 1.5649 - val_acc: 0.4529\n",
      "Epoch 5/10\n",
      "8s - loss: 1.4767 - acc: 0.4795 - val_loss: 1.5167 - val_acc: 0.4667\n",
      "Epoch 6/10\n",
      "8s - loss: 1.4436 - acc: 0.4901 - val_loss: 1.5346 - val_acc: 0.4590\n",
      "Epoch 7/10\n",
      "8s - loss: 1.4128 - acc: 0.5024 - val_loss: 1.5218 - val_acc: 0.4592\n",
      "Epoch 8/10\n",
      "8s - loss: 1.3856 - acc: 0.5113 - val_loss: 1.5083 - val_acc: 0.4724\n",
      "Epoch 9/10\n",
      "8s - loss: 1.3623 - acc: 0.5220 - val_loss: 1.4772 - val_acc: 0.4755\n",
      "Epoch 10/10\n",
      "8s - loss: 1.3406 - acc: 0.5251 - val_loss: 1.4747 - val_acc: 0.4784\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.4494222885131836, 0.4874]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing Number of Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=3072))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9s - loss: 1.8316 - acc: 0.3386 - val_loss: 1.6950 - val_acc: 0.3961\n",
      "Epoch 2/10\n",
      "10s - loss: 1.6298 - acc: 0.4205 - val_loss: 1.6117 - val_acc: 0.4294\n",
      "Epoch 3/10\n",
      "9s - loss: 1.5411 - acc: 0.4501 - val_loss: 1.5669 - val_acc: 0.4456\n",
      "Epoch 4/10\n",
      "9s - loss: 1.4834 - acc: 0.4704 - val_loss: 1.5115 - val_acc: 0.4665\n",
      "Epoch 5/10\n",
      "9s - loss: 1.4343 - acc: 0.4905 - val_loss: 1.5095 - val_acc: 0.4706\n",
      "Epoch 6/10\n",
      "9s - loss: 1.3947 - acc: 0.5048 - val_loss: 1.4652 - val_acc: 0.4905\n",
      "Epoch 7/10\n",
      "9s - loss: 1.3574 - acc: 0.5162 - val_loss: 1.4571 - val_acc: 0.4899\n",
      "Epoch 8/10\n",
      "10s - loss: 1.3209 - acc: 0.5293 - val_loss: 1.4494 - val_acc: 0.4951\n",
      "Epoch 9/10\n",
      "9s - loss: 1.2917 - acc: 0.5379 - val_loss: 1.4196 - val_acc: 0.5055\n",
      "Epoch 10/10\n",
      "10s - loss: 1.2579 - acc: 0.5530 - val_loss: 1.4453 - val_acc: 0.4963\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.4105119270324706, 0.50139999999999996]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Learning Rate - \n",
    "\n",
    "Decreasing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=3072))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "9s - loss: 2.0089 - acc: 0.2860 - val_loss: 1.8964 - val_acc: 0.3362\n",
      "Epoch 2/10\n",
      "9s - loss: 1.8268 - acc: 0.3625 - val_loss: 1.8098 - val_acc: 0.3557\n",
      "Epoch 3/10\n",
      "9s - loss: 1.7534 - acc: 0.3865 - val_loss: 1.7696 - val_acc: 0.3750\n",
      "Epoch 4/10\n",
      "9s - loss: 1.7022 - acc: 0.4059 - val_loss: 1.7231 - val_acc: 0.3907\n",
      "Epoch 5/10\n",
      "9s - loss: 1.6598 - acc: 0.4229 - val_loss: 1.6880 - val_acc: 0.4073\n",
      "Epoch 6/10\n",
      "8s - loss: 1.6236 - acc: 0.4350 - val_loss: 1.6566 - val_acc: 0.4235\n",
      "Epoch 7/10\n",
      "9s - loss: 1.5936 - acc: 0.4436 - val_loss: 1.6373 - val_acc: 0.4295\n",
      "Epoch 8/10\n",
      "9s - loss: 1.5657 - acc: 0.4537 - val_loss: 1.6113 - val_acc: 0.4313\n",
      "Epoch 9/10\n",
      "11s - loss: 1.5430 - acc: 0.4616 - val_loss: 1.5951 - val_acc: 0.4410\n",
      "Epoch 10/10\n",
      "9s - loss: 1.5207 - acc: 0.4685 - val_loss: 1.5764 - val_acc: 0.4481\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.5425354846954347, 0.45760000000000001]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Learning Rate - \n",
    "\n",
    "Increasing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=3072))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.05, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10s - loss: 1.8959 - acc: 0.3087 - val_loss: 1.7641 - val_acc: 0.3601\n",
      "Epoch 2/10\n",
      "9s - loss: 1.7308 - acc: 0.3762 - val_loss: 1.6895 - val_acc: 0.3953\n",
      "Epoch 3/10\n",
      "9s - loss: 1.6793 - acc: 0.3965 - val_loss: 1.6641 - val_acc: 0.4098\n",
      "Epoch 4/10\n",
      "8s - loss: 1.6492 - acc: 0.4090 - val_loss: 1.6812 - val_acc: 0.4069\n",
      "Epoch 5/10\n",
      "8s - loss: 1.6240 - acc: 0.4207 - val_loss: 1.6604 - val_acc: 0.4037\n",
      "Epoch 6/10\n",
      "10s - loss: 1.6053 - acc: 0.4275 - val_loss: 1.6354 - val_acc: 0.4237\n",
      "Epoch 7/10\n",
      "9s - loss: 1.5928 - acc: 0.4308 - val_loss: 1.6532 - val_acc: 0.4190\n",
      "Epoch 8/10\n",
      "9s - loss: 1.5856 - acc: 0.4354 - val_loss: 1.6420 - val_acc: 0.4253\n",
      "Epoch 9/10\n",
      "8s - loss: 1.5692 - acc: 0.4391 - val_loss: 1.6051 - val_acc: 0.4314\n",
      "Epoch 10/10\n",
      "8s - loss: 1.5578 - acc: 0.4418 - val_loss: 1.6478 - val_acc: 0.4132\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.6207207927703857, 0.42280000000000001]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='sigmoid', input_dim=3072))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "11s - loss: 1.9583 - acc: 0.2986 - val_loss: 1.8463 - val_acc: 0.3395\n",
      "Epoch 2/10\n",
      "9s - loss: 1.7721 - acc: 0.3722 - val_loss: 1.7676 - val_acc: 0.3750\n",
      "Epoch 3/10\n",
      "8s - loss: 1.6909 - acc: 0.4018 - val_loss: 1.7084 - val_acc: 0.3935\n",
      "Epoch 4/10\n",
      "8s - loss: 1.6325 - acc: 0.4221 - val_loss: 1.6475 - val_acc: 0.4232\n",
      "Epoch 5/10\n",
      "9s - loss: 1.5856 - acc: 0.4370 - val_loss: 1.6098 - val_acc: 0.4335\n",
      "Epoch 6/10\n",
      "9s - loss: 1.5521 - acc: 0.4485 - val_loss: 1.5822 - val_acc: 0.4439\n",
      "Epoch 7/10\n",
      "9s - loss: 1.5188 - acc: 0.4623 - val_loss: 1.5554 - val_acc: 0.4505\n",
      "Epoch 8/10\n",
      "9s - loss: 1.4880 - acc: 0.4720 - val_loss: 1.5377 - val_acc: 0.4577\n",
      "Epoch 9/10\n",
      "10s - loss: 1.4616 - acc: 0.4840 - val_loss: 1.5045 - val_acc: 0.4687\n",
      "Epoch 10/10\n",
      "9s - loss: 1.4356 - acc: 0.4897 - val_loss: 1.4996 - val_acc: 0.4714\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.4703817983627319, 0.47649999999999998]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=3072))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "10s - loss: 1.9530 - acc: 0.3023 - val_loss: 1.8099 - val_acc: 0.3677\n",
      "Epoch 2/10\n",
      "9s - loss: 1.7360 - acc: 0.3855 - val_loss: 1.6959 - val_acc: 0.3971\n",
      "Epoch 3/10\n",
      "10s - loss: 1.6307 - acc: 0.4224 - val_loss: 1.6076 - val_acc: 0.4330\n",
      "Epoch 4/10\n",
      "9s - loss: 1.5628 - acc: 0.4456 - val_loss: 1.6165 - val_acc: 0.4259\n",
      "Epoch 5/10\n",
      "9s - loss: 1.5130 - acc: 0.4623 - val_loss: 1.5709 - val_acc: 0.4442\n",
      "Epoch 6/10\n",
      "8s - loss: 1.4756 - acc: 0.4744 - val_loss: 1.5236 - val_acc: 0.4556\n",
      "Epoch 7/10\n",
      "10s - loss: 1.4360 - acc: 0.4897 - val_loss: 1.5169 - val_acc: 0.4563\n",
      "Epoch 8/10\n",
      "9s - loss: 1.4072 - acc: 0.5001 - val_loss: 1.4783 - val_acc: 0.4746\n",
      "Epoch 9/10\n",
      "9s - loss: 1.3791 - acc: 0.5102 - val_loss: 1.4655 - val_acc: 0.4819\n",
      "Epoch 10/10\n",
      "8s - loss: 1.3510 - acc: 0.5203 - val_loss: 1.4395 - val_acc: 0.4862\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.4225452732086181, 0.49359999999999998]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Dropout rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_dim=3072))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "11s - loss: 1.9281 - acc: 0.2970 - val_loss: 1.8317 - val_acc: 0.3449\n",
      "Epoch 2/10\n",
      "10s - loss: 1.7662 - acc: 0.3686 - val_loss: 1.6951 - val_acc: 0.3926\n",
      "Epoch 3/10\n",
      "10s - loss: 1.7056 - acc: 0.3893 - val_loss: 1.6324 - val_acc: 0.4227\n",
      "Epoch 4/10\n",
      "10s - loss: 1.6577 - acc: 0.4098 - val_loss: 1.6140 - val_acc: 0.4272\n",
      "Epoch 5/10\n",
      "9s - loss: 1.6220 - acc: 0.4200 - val_loss: 1.5606 - val_acc: 0.4498\n",
      "Epoch 6/10\n",
      "9s - loss: 1.5870 - acc: 0.4337 - val_loss: 1.5549 - val_acc: 0.4452\n",
      "Epoch 7/10\n",
      "9s - loss: 1.5680 - acc: 0.4373 - val_loss: 1.5499 - val_acc: 0.4565\n",
      "Epoch 8/10\n",
      "9s - loss: 1.5472 - acc: 0.4462 - val_loss: 1.5206 - val_acc: 0.4560\n",
      "Epoch 9/10\n",
      "8s - loss: 1.5266 - acc: 0.4517 - val_loss: 1.5068 - val_acc: 0.4625\n",
      "Epoch 10/10\n",
      "9s - loss: 1.5122 - acc: 0.4585 - val_loss: 1.4778 - val_acc: 0.4797\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.4578220039367675, 0.48659999999999998]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
